import { NextRequest, NextResponse } from "next/server";
import { OpenAI } from "openai";

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY!,
});

export async function POST(req: NextRequest) {
  try {
    const { content, replies } = await req.json();

    // æœ€æ–°ã®è¿”ä¿¡3ä»¶ã®ã¿ä½¿ç”¨ï¼ˆã‚ã‚Œã°ï¼‰
    const recentReplies = (replies || [])
      .slice(-3)
      .map((r: any) => `ãƒ»${r.content}`);

    console.log("ğŸŸ© æŠ•ç¨¿å†…å®¹:", content);
    console.log("ğŸŸ¦ è¿”ä¿¡ï¼ˆæœ€æ–°3ä»¶ï¼‰:", recentReplies);

    const prompt = `
ä»¥ä¸‹ã¯SNSã§ã®æŠ•ç¨¿ã¨ã€ãã‚Œã«å¯¾ã™ã‚‹è¿”ä¿¡ã®ä¸€éƒ¨ã§ã™ã€‚
ã¾ãšæŠ•ç¨¿å†…å®¹ã‚’ã‚ˆãèª­ã¿ã€æŠ•ç¨¿è€…ã®æ„å›³ã‚„æ‚©ã¿ã«ä¸å¯§ã«å¯„ã‚Šæ·»ã£ã¦ãã ã•ã„ã€‚
ãã®ã†ãˆã§ã€ã‚‚ã—è¿”ä¿¡ã®ä¸­ã«å‚è€ƒã«ãªã‚‹æ„è¦‹ãŒã‚ã‚Œã°è€ƒæ…®ã—ã¦ã‚‚æ§‹ã„ã¾ã›ã‚“ã€‚

æŠ•ç¨¿è€…ã«å¯¾ã—ã¦å»ºè¨­çš„ã§æ€ã„ã‚„ã‚Šã®ã‚ã‚‹ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ã€æ—¥æœ¬èªã§ä¸å¯§ã«æä¾›ã—ã¦ãã ã•ã„ã€‚
èª¤å­—è„±å­—ã‚’æŒ‡æ‘˜ã—ãŸã‚Šã€æ¨æ¸¬ã§å†…å®¹ã‚’è£œã£ãŸã‚Šã›ãšã€å˜˜ã®æƒ…å ±ã‚’é¿ã‘ã€å„ªã—ãã‚µãƒãƒ¼ãƒˆã—ã¦ãã ã•ã„ã€‚

ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã¯500æ–‡å­—ä»¥å†…ã§ãŠé¡˜ã„ã—ã¾ã™ã€‚

â–  æŠ•ç¨¿å†…å®¹ï¼š
${content}

â–  æœ€è¿‘ã®è¿”ä¿¡ï¼š
${recentReplies.length > 0 ? recentReplies.join("\n") : "ï¼ˆè¿”ä¿¡ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ï¼‰"}
`;

    const chat = await openai.chat.completions.create({
      model: "gpt-4",
      messages: [{ role: "user", content: prompt }],
    });

    const result = chat.choices[0].message.content?.trim();
    return NextResponse.json({ result });
  } catch (e) {
    console.error("âŒ ã‚¨ãƒ©ãƒ¼:", e);
    return NextResponse.json(
      { error: "AIåŠ©è¨€ã«å¤±æ•—ã—ã¾ã—ãŸ" },
      { status: 500 }
    );
  }
}
